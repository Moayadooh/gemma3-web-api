
Chat with LLM:
docker model run ai/gemma3 'Hello'

Make the file executable:
chmod +x chat.sh

Chat and save the conversation:
./chat.sh 'Hello'
